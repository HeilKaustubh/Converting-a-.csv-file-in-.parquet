import org.apache.spark.sql.{SQLContext, SparkSession}

object dfduplicate {
  def main(args: Array[String]): Unit = {

    val sparkSession = SparkSession.builder.
      master("local")
      .appName("spark session example")
      .getOrCreate()


    val df = sparkSession.read.option("header", "true").
      csv("C:\\Users\\xx\\Desktop\\TestFile2.csv")


    df.write.parquet("C:\\Users\\xx\\Desktop\\TestFile2.parquet")
  }
}

